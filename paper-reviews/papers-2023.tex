\input{papers.tex}

\begin{document}

A total of \total{citenum} papers read in the year.

\section*{Simulators}

\begin{itemize}
    \item \cite{Dahl:Ericsson-VP:2016}:

    Ericsson's experience with virtual platform for pre-silicon software development. The virtual platforms are based on SystemC/TLM. This paper may be used as a showcase of simulation importance.

    \item \cite{Dall:KVM-ARM:2014}:

    The paper describes an early design of KVM/ARM port using the first version of ARM virtualization hardware support. Authors claim to introduce a novel "split-mode" virtualization approach as a way to run hypervisor simultaneously in different CPU privileged modes. This approach is not new though in my opinion. There exists for a long time hypervisors like Simics that use both kernel and user CPU modes to leverage different parts of CPU virtualization. Nevertheless, authors have done a grade work adding ARM support to KVM with generic and rather minimal changes to KVM and Linux kernel. There is an interesting comparison of x86 and ARM virtualization power and performance overheads in the paper. Some of the links in references are also worse looking through later.

    \item \cite{Menard:SystemC-gem5:2017}:

    The article provides a short summary of transaction-based communication in SystemC TLM and in gem5. However the main focus of the paper is on an adapter layer between SystemC TLM and gem5 transactions. The layer provides bi-directional translation for the transaction. The layer was tested on a special-purpose worse-case setup and a couple of more realistic workflows. On the worst-case scenario the layer demonstrated roughly 2x slowdown compared to SystemC only. The integration is claimed to be merged to gem5 official repo.

    \item \cite{Sandberg:FullSpeedAhead:2015}:

    The article describes an approach for fast full-system cycle-accurate simulation to enable efficient hardware and software co-design. The approach address fixed-software limitation of the standard checkpoint-based critical path cycle-accurate simulation approach. First, the authors reduced the porting of functional warming for the samples and introduced error estimation algorithm for cache warming. The error estimation compares best- and worst-case results (run in parallel) to determine whether limited functional warming has significant effect on the results or not. The technique is named Full Speed Ahead. The authors extended the technique with parallel sample execution. The main idea of the parallel Full Speed Ahead approach is to break target workload into samples and execute the samples in parallel while fast-forwarding to the sample boundaries using hardware-supported virtualization. As result, the authors claims to achieve near-native simulation speed while running on a wide enough (in terms of processor cores) host systems.

    \item \cite{Patel:MARSS:2011}:

    The article is about Micro Architectural and System Simulator (MARSS). The simulator is constructed as a combination of QEMU and PTLSim. PTLSim and QEMU share the same processor structure which allows them to switch seamlessly thus providing a gear-shit capability for mixing functional and cycle-accurate execution. QEMU provides all the peripherals in the setup. The article uses term emulation for function models and simulation for cycle-accurate models. This is another view on this controversial topic that can be a reference for the \href{https://github.com/yulyugin/sim-lectures}{<<Fundamentals of Full-Platform Simulation>>} course.

    \item \cite{Moore:Imperas-Custom-RISCV:2019}:

    The article describes a standard way of adding new processor instructions purely based on instruction count: find a pattern, add instruction, makes sure it works, measure instruction count to estimate how performance changes, repeat it needed. The approach is applied to RISC-V processors using IMPERAS ISS. Could be a good reference for students who are not aware how this could be done.

    \item \cite{Thompson:CGCMonitor:2018}:

    The article is a good demonstration of what can be achieved using analysis capabilities provided by a simulation system. Authors of the paper built vetting system for a cyber challenge. The main purpose of the system was to make sure that none of the competitors is trying to subvert the competition infrastructure. The vetting system was build on top of Simics hap and breakpoint capabilities thus providing non-intrusive analysis with support for reverse execution.
\end{itemize}

\section*{Processors}
\begin{itemize}
    \item \cite{Gwennap:ARM-Neoverse:2019}:

    A 64 core ARM reference server CPU design similar to Cortex-A76 microarchitecture. Single core performance is not that good but the processor is expectedly much more power efficient. New hardware-based coherence model for i-cache aiming improvement for multiple VM performance. SPEC CPU 2006 is still referenced as a benchmark. Interesting reference to read --- <<Editorial: Intel Hides Behind ICC>> --- MPR claims that ICC must be approximately 30\% faster than GCC (at least for SPEC workloads).

    \item \cite{Demler:Helios:2019}:

    The article describes ARM 64-bit only architecture called Helios. It is a first licensable CPU that combines OOO and multithreaded execution. The main application for the processor are data transfer infrastructure and automotive industry. The processor architecture supports INT8 and FP16 formats that are the current trend for DNN acceleration. On top of INT8 and FP16 the processor can be closely integrated with various accelerators.

    \item \cite{Eyre:DSP-Derby:2001}:

    The article presents digital signal processor's (DSP) design and development challenges. The author compares techniques used in DSPs with techniques typical for general-purpose processors. The article emphasizes DSP's requirement for predictable executing speed that is often more important than performance. The requirement is of course harder to fulfill with caches and out-of-order execution. VLIW, SIMD and highly compressed encodings are mentioned as an example of techniques prevailing in DPSs. There is also performance comparison of some DSPs with a superscalar processor that is based on FFT and FIR filter benchmarks.

    \item \cite{Charles:TruboBoostEvaluation:2009}:

    The article presents evaluation of Intel's Turbo Boost technology first introduce in Nehalem microarchitecture. The technology may increase the processor's frequency when load and temperature are low. SPEC CPU2006 is used as benchmark for the evaluation. Benchmark suites are classified as CPU-intensive and memory-intensive based on LLC cache-miss rate. The authors perform three kind of tests:

    \begin{enumerate}
        \item Isolation tests --- every benchmark runs in isolation with and without Turbo Boost to measure speedup that can be achieved through the frequency increase.
        \item Paired tests --- pairs of the benchmarks run simultaneously to test if the process can still make effective use of Turbo Boost.
        \item Saturation tests --- all processor cores are loaded with different combination of CPU- and memory-intensive benchmarks to test whether Turbo Boost activates when all cores are loaded.
    \end{enumerate}

    One interesting observation from the results is that for saturation tests maximum Turbo Boost activation is not always corresponds to the best overall performance of the system.

    Another set of tests described in the paper is multi-threaded workloads from PARSEC and BLAST benchmark suits. The idea behind the tests is also pretty interesting: according to Amdahl's law speedup of parallel application is limited by its sequential component. The authors check whether Amdahl's law can be mitigated through the frequency increase during the sequential execution. There is a very interesting citation about that in the paper that is worse looking at later and is probably a good source for \href{https://github.com/yulyugin/mipt-parallel-computing}{<<MIPT parallel computing>> course}.
\end{itemize}

\section*{Compilers}
\begin{itemize}
    \item \cite{Pharr:ispc:2012}:

    The paper presents ispc --- Intel SPMD Program Compiler. A new <<SPMD-on-SIMD>> concept is introduced. The concept seems to be quite reasonable for efficient compilation of SPMD programs for CPUs. A few specific optimizations are described to enable better usage of a CPU's SIMD hardware unit. The project looks like an interesting alternative to hand-written intrinsic-based optimizations. The project is still alive at the moment of writing the note. I can also see a few well familiar names in the list of contributors. As a side note for myself, the paper can be a good reference for \href{https://github.com/yulyugin/mipt-parallel-computing}{<<MIPT parallel computing>> course} if that one ever gets back to live.
\end{itemize}

\section*{Testing}
\begin{itemize}
    \item \cite{Regehr:C-Reduce:2012}:

    As practice shows creating a concise reproducer for a bug is sometimes as complex as fixing the bug. Compiler bugs can be especially hard to report as they are usually observed on real and rather big projects. Even relatively small \href{https://yulyugin.github.io/blog/2022/icc-bug}{compiler bug} reproducers could be hard to analyze and report. Authors of the paper tried to address this important issue by implementing an automatic test case reducers for C.

    \item \cite{Easson:FrobOS:2012}:

    The article describes the ideas behind VMware's minimalistic test operating system FrobOS. Tbe operating system is a great instrument for bare-metal hardware tests. The tooling around the OS also enables nice and fast testing for their hypervisor: simple ways to run port and run the tests between different CPU and hypervisor modes.

    \item \cite{Burns:IntelHTTValidation:2002}:

    The article shares a story and decisions made during Intel's Hyper Threading Technology pre-silicon validation. Some implementation details of the technology are described as well. The amount of tests that needs to be performed explodes when going from single logical core system to the hyper threaded system. All the state now falls into four categories: duplicated, partitioned, entry tagged and fully shared. The four state categories together with new modes of operation lead to test explosion. One of the interesting solutions was to switch between logical threads for regular testing instead of of always testing both. The authors also made an interesting post mortem analysis of both issues discovered during pre-silicon validation and the issues found in silicon.
\end{itemize}

\section*{Computer Architecture}
\begin{itemize}
    \item \cite{Philips:VLIW:1997}:

    Nice high level overview of VLIW architecture and comparison with typical RISC and CISC designs. Great reference for students to show the basic concepts of CPU architectures even though it is not fully relevant anymore.

    \item \cite{Colwell:Multiflow-VLIW:1987}:

    The paper describes a VLIW architecture developed by Multiflow Corporation. It is one of the VLIW pioneering designs. It is always enjoyable to read old papers about computer architecture trends and ideas; compare the old ideas and expectations with how it turned out now: <<a VLIW machine was expected to provide from ten to thirty times the performance of a more conventional machine built of the same implementation technology>>. A great comments for the citation would be something like: <<if only we would have smart enough compiler>>. Industry practice so far showed that VLIW could be an amazing architecture for some DSPs while a superscalar processor delivers better results for general purpose usage.

    \item \cite{Rajwar:SpeculativeLockElision:2001}:

    The paper describes Speculative Lock Elision --- CPU microarchitectural technique aimed to support transaction memory. The proposed technique suggests automatic detection and elision of lock acquire and release instructions if and only if a processor can guarantee atomic memory updates between the locks. No ISA level changes are required. The existing cache coherency mechanism can to be used to guarantee atomicity. The technique's behavior is similar to how a branch predictor speculation works --- assume that lock can be elided, elide the lock, roll-back if the assumption turned out to be wrong, commit the results otherwise. The roll-back can be achieved either using reorder buffer (ROB) or register checkpointing. The later allows larger critical sections to be speculated. Speculative Lock Elision supports nested locks --- only one (can be the outer one) of the locks is elided in that case. Intel has implemented the technique in its Hardware Lock Elision (HLE) extension that is well known for its bugginess. HLE is now deprecated and removed from the latest processors.
\end{itemize}

\section*{Autonomous Driving}
\begin{itemize}
    \item \cite{Delmer:Mobileye:2019}:

    The article present an overview of Mobileye existing and in flight processors for advanced-driver-assistance-systems (ADAS). The article also presents a simplistic comparison with Nvidia GPU-based solutions for the area. The main comparison metrics are trillion operations per second (TOPS) and efficiency which is measured as TOPS divided by power consumption. It is an overall nice basic overview of what is happening in the area with cool examples of 360-degree image construction and object classification.
\end{itemize}

\section*{Machine Learning}
\begin{itemize}
    \item \cite{Wheeler:Optical-AI:2019}:

    Optical computing for AI moves closer to commercialization. Startups originating from MIT and Princeton demonstrate interesting optical computing for AI solutions. The systems are targeting convolutional neural networks. 2D filtering is equal to 2D convolution. The approach is aimed to reduce heat and power consumption and of course improve performance simultaneously. One of the main problems so far is optical to electrical and electrical to optical signal conversion. Solutions for the problem seems to be a key for high performance at the moment. The article also contains a link to a scientific paper with more details.

    \item \cite{Gwennap:Centaur-AI:2019}:

    Centaur has developed an x86 processor with deep-learning accelerator --- Ncore. The accelerator has a typical design for the field of application: it's a VLIW architecture relying on traditional SIMD approach with smaller sized vector elements like INT8, BF16, etc. The architecture is 64 times wider that Intel's AVX-512. The x86 cores are alike low-end Skylake cores but it can achieve better neural network performance thanks to the accelerator. Centaur has also constructed a basic software stack that convert TensorFlow to an internal graph format that is later compiled into Ncore assembly - another typical approach for deep-learning accelerators. The article reports that so fat Centaur's software can only handle inference but not training.

    \item \cite{Abadi:TensorFlow:2016}:

    The article describes ideas and reasons that stay behind TensorFlow. Nowadays one can hardly imaging machine learning without TensorFlow. All the accelerators I know about have support for TensorFlow or aim to support it. To represent computations, TensorFlow uses a single dataflow graph where vertices represent operations (atomic units of computations) and edges represent input and output to a vertex. The dataflow graph can be broken into subgraphs and distributed between multiple servers for execution. Basic control flow is supported using \texttt{Switch} and \texttt{Merge} operations. The system provides support for CPUs, GPUs, Google TPUs and allows extensions for other hardware systems.

    \item \cite{Micikevicius:FP8ForDL:2022}:

    The article describes two new 8-bit floating point formats: E4M3 and E5M2. The formats are a natural progression of the current trend of data type shrinking that is aimed to improve computational efficiency of machine learning training and inference. One of the formats --- E5M2 --- can be trivially converted to FP16. In a similar way that bfloat16 can be converted to FP32. The authors show that results of training and inference done using the new formats effectively matches the results achieved by 16-bit formats.

    \item \cite{Vaswani:Attention:2023}:

    The article proposes the Transformer machine learning network architecture that is solely based on attention mechanisms. The authors show that the new models are superior compared to recurrent or conventional neural networks when applied to machine translation tasks.

    \item \cite{Dao:FlashAttention:2022}:

    The article proposes FlashAttention, an IO-aware exact attention algorithm focused on reducing of read/write accesses between GPU on-chip SRAM and high bandwidth memory (HBM). The authors analyze IO complexity of the algorithm, showing that it required fewer HBM accesses than standard attention algorithm. The article also extends FlashAttention to block-sparse attention, an approximate attention algorithm. FlashAttention algorithm is based on kernel fusion (most common approach to accelerate memory-bound operations by loading data from HDM once and applying it to several operators, instead of loading it multiple times for each operator) and tiling (computation using blocks instead of the full dataset). The authors demonstrated both training speed and accuracy/perplexity improvements because of larger context allowed by faster training.
\end{itemize}

\section*{Virtual Machines}
\begin{itemize}
    \item \cite{Rosenblum:VMM-trends:2005}:

    The article includes a very concise VMM history and some basic techniques like \textit{shadow paging}. Strict focus of the article is on VMware's solutions of that time. There described one interesting paravirtualization idea I didn't know about before --- \textit{ballon process} running inside a Guest OS and communicating with the VMM. The process can allocated a bunch of memory thus forcing the Guest OS to use its knowledge about other processes to page unused memory out. VMM thus can also page out this memory and then reclaim the memory used by the \textit{ballon process} - nice trick.
\end{itemize}

\section*{Binary Translation}
\begin{itemize}
    \item \cite{Altman:BT-Future:2001}:

    The article provides a nice overview of Transmeta Crusoe and IBM DAISY with some insides on the special-purpose underlying hardware. There is an overview of other binary translation systems including LaTTe JVM. There is a clear focus on speculative operations to be performed by Crusoe and DAISY binary translators. One optimization had a bit unclear benefits when I read the article --- the speculative loads performed by DAISY. While reading the article I only thought about the speculative operation as a cache warmup for the later reload. The problem here is that speculative loads could overlap with stores performed before the actual load should occur. To address this issue DAISY uses a \textbf{load-verify} operations that is insert to the location of the original load. The operation reloads the memory value and compares it with the speculatively pre-loaded one. Depending on the result DAISY either continues as normal or enters recovery mode. While writing the note I realized that the load speculation might allow other speculations to be performed and thus the recovery mode is needed to roll them back if the load is overlapped. The article points to the \href{https://patents.google.com/patent/US5758051A}{US5758051A} patent with more details that could be worse to read later.

    \item \cite{Hamayun:StaticBT-VLIW:2013}:

    One of the most confusing papers I read. Unclear why KVM is described in the paper what is the so <<native>> about that approach. I can see two well-known ideas in the paper --- cross-platform compilation and static binary translation. Main focus of the paper is on static binary translation for VLIW CPUs. There is a good description of VLIW weirdness like register dependencies withing the package and delay slots. The authors built a static binary translation that is capable of handling all the tricky VLIW peculiarities.

    \item \cite{Qin:ParallelJIT:2006}:

    The paper proposes a parallel JIT-compilation technique for ISSes. The idea behind technique is rather primitive. Here is a short summary:

    \begin{enumerate}
        \item Interpreter runs and collects statistics about block usage.
        \item Once a hot block is detected it is added to compilation queue.
        \item Compilation workers run in parallel host threads. C++ code is generated for each block. GCC is used to compile the blocks to DLLs.
        \item DLLs are loaded and used to simulate the block.
    \end{enumerate}

    Self-modifying code is supported through monitoring of writes to compiled blocks. The authors also added a DLL cache to avoid compilation overhead for subsequent runs of the same simulation. Easy to read article that would be a good reference for \href{https://github.com/yulyugin/sim-lectures}{<<Fundamentals of Full-Platform Simulation>>} MIPT course.
\end{itemize}

\section*{Performance}
\begin{itemize}
    \item \cite{Yasin:TopDownCPUPerfAnalysis:2014}:

    The paper proposes a top down performance analysis method for superscalar out-of-order processors. The paper discusses a couple of challenges for low-level CPU performance analysis; problems and limitation of the existing methods. The paper suggest a tree-like structure for the analysis. The top level of the hierarchy includes front end, bad speculations, retiring and frontend. Looking at specific part of the hierarchy allows to disregard events happening at other parts thus narrowing down the problem while moving to the leaves of the hierarchy. The author presented few usage examples of the methods and proposed changes to Intel's performance monitoring unit architecture.
\end{itemize}

\section*{Static Analysis}
\begin{itemize}
    \item \cite{Distefano:StaticAnalysisFB:2019}:

    The paper presents Infer and Zoncolan (security analysis) --- static analysis tools developed and used by Facebook. On top of standard false positive and false negative metrics authors added fix rate metric measuring the proportion of reported issues that were actually fixed. One of the observation is that the fix rate gets closer to 70\% when the static analysis is applied during diff (pull request) time. Meanwhile, the fix rate is near zero when static analysis is applied once on the entire code base. The overall approach to development of the static analysis tools looks very reasonable to me including the initial ideas, integration and addition of new rules. I would definitely recommend to read this paper for anyone who is going to work on custom static analysis tools. So far the approach looks to be the most reasonable static analysis application I saw in the industrial projects I worked on. Infer is available as open source and I should definitely try it on current projects.
\end{itemize}

\section*{GPU}
\begin{itemize}
    \item \cite{Yilmazer:ScalarWaving:2014}:

    The authors discovered that GPU programs contain significant portion of scalar instructions. 30\% for the GPU selected benchmarks in the paper. The papers states that scalar instructions are typically executed as SIMD with all vector elements having the same values. Thus, the same computation is performed redundantly. One of the solution for the problem is to run the calculations once and than broadcast the results in order to reduce power consumption on unnecessary operations. The authors suggested to statically detect scalar operations during compilations. One negative effect of this is reduced utilization of SIMD lanes. To improve utilization the  paper proposed scalar waving --- grouping of same scalar instructions processing different scalars into a single SIMD instruction. This grouping is suggest to be performed during runtime through by GPU itself. Further, the authors developed simultaneous scalar and SIMD group waving --- grouping and a SIMD instructions and scalar ware. GPU needs to be able to execute two different operations as a part of SIMD instruction in this case. The authors claim to achieve up to 25\% percent performance improvement for the selected benchmarks. The performance studies are performed on \href{https://github.com/gpgpu-sim}{GPGPU-Sim} simulator.

    \item \cite{Fung:DynamicWrapGPUControlFlow:2007}:

    The paper is focused on GPGPU control flow problems that represent general control flow issues with SIMD --- what should be done if control flow diverges for SIMD lines. The paper describes several possible solutions for the problem: scalar execution (more typical for CPUs), reconvergence at the immediate post-dominator, dynamic warp formation that is supposed to improve SIMD pipeline utilization. The authors show that reconvergence at the immediate post-dominator is not always the best choice. They propose an implementation of dynamic warp formation together with several heuristics that are supposed to define when the formed warps should be pushed for execution. The authors claim that dynamic warp formation improves performance by 20.7\% on average compared to reconvergence at the immediate post-dominator. They estimated that area increase because of the proposed hardware changes to be around 4.7\%.
\end{itemize}

\section*{Software Attacks}
\begin{itemize}
    \item \cite{Wahbe:SoftwareFaultIsolation:1993}:

    The authors proposed a software technique aimed to isolate faults in third party software modules loaded as extension. The idea is to run both the main module and the submodules in one address space to avoid expansive RPC communication. Fault isolation is supposed to be achieved through binary patching which is implemented on compile time by the authors. Each modules has a dedicated part of the shared memory space. The modules are not supposed to access other module's memory regions. To achieve that every memory access or jump that uses indirect address is wrapped by a special instruction sequence ensuring isolation. Few registers are considered to be special purpose registers and thus reserved for use by the isolation mechanism. Trusted modules like the core module do not need to be modified and thus avoid the patching overhead. Intra module communication is supposed to be done through an intermediate memory space using special call mechanism. Operation is system should be modified to protect one module from closing resources like file descriptors of another module. The authors report one to two orders of magnitude performance improvement compared to existing at that moment RPC mechanisms.

    \item \cite{Murdock:Plundervolt:2020}:

    The authors discovered an attack vector to Intel SGX through processor undervolting which is available on modern processors via undocumented MSRs. In Intel SGX's model, both OS and physical access are considered to be untrusted. In my opinion this is enough to make the technology rather questionable. This paper proves my doubts about the technology. Intel's response to the problem was quite expected - simply hide the undocumented voltage control MSRs thus hiding the problem without actually fixing it. I admit, it must be a pain to protect against such kind of attacks. Microsoft has a nice software guarding against overflows that may be in this particular case caused by faulty multiplication --- divide the result and compare it with then incoming operands.
\end{itemize}

\section*{Collective Communication}
\begin{itemize}
    \item \cite{Thakur:MPIOptimization:2005}:

    The article presents different high-performance implementations of collective MPI operations. The authors assume that the time to send similar package between any two nodes is the same and does not depend on number of concurrent communications. This is a very simple cost model but seems to be sufficient for the author's needs. The article is a good source for different one-to-all, all-to-one, all-to-all communication algorithms. Interesting but expected idea from the article is to use different communication algorithms depending on message size.

    \item \cite{Rashidi:AstraSim:2020}:

    The article present ASTra-Sim --- simulator and modeling approach aimed to navigate SW/HW design space of distributed deep learning training platforms. The paper justifies the need of such simulation defining some basic concepts used in the field. ASTra-Sim is based on Garnet (part of GEM5) network simulator and uses event-driven execution model. ASTra-Sim implements topology-aware collective operations and different parallelism approaches of training. ASTra-Sim provides interfaces for compute and network simulators allowing to replace the default implementation with other simulators. The research is focused on network topologies and have description for how different communication operations can be mapped on the studied topologies. The study is focused on torus and all-to-all topologies and hierarchical versions of the above.
\end{itemize}

\end{document}
