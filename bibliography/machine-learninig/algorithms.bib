@misc{Dao:FlashAttention:2022,
  author        = {Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and Christopher RÃ©},
  title         = {FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness},
  year          = {2022},
  archiveprefix = {arXiv},
  eprint        = {2205.14135},
  primaryclass  = {cs.LG},
}

@inproceedings{Fu:FlashFFTConv:2024,
  author    = {Daniel Y Fu and Hermann Kumbong and Eric Nguyen and Christopher Re},
  title     = {Flash{FFTC}onv: Efficient Convolutions for Long Sequences with Tensor Cores},
  year      = {2024},
  booktitle = {The Twelfth International Conference on Learning Representations},
  url       = {https://openreview.net/forum?id=gPKTTAfYBp},
}

@inproceedings{Poli:Hyena:2023,
  author    = {Poli, Michael and Massaroli, Stefano and Nguyen, Eric and Fu, Daniel Y. and Dao, Tri and Baccus, Stephen and Bengio, Yoshua and Ermon, Stefano and R\'{e}, Christopher},
  title     = {Hyena hierarchy: towards larger convolutional language models},
  year      = {2023},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  articleno = {1164},
  location  = {Honolulu, Hawaii, USA},
  numpages  = {36},
  publisher = {JMLR.org},
  series    = {ICML'23},
}
@misc{Vaswani:Attention:2023,
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  title         = {Attention Is All You Need},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {1706.03762},
  primaryclass  = {cs.CL},
}