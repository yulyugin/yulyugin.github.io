@misc{Dao:FlashAttention:2022,
  author        = {Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and Christopher RÃ©},
  title         = {FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness},
  year          = {2022},
  archiveprefix = {arXiv},
  eprint        = {2205.14135},
  primaryclass  = {cs.LG},
}

@inproceedings{Dao:Monarch:2022,
  author    = {Dao, Tri and Chen, Beidi and Sohoni, Nimit S and Desai, Arjun and Poli, Michael and Grogan, Jessica and Liu, Alexander and Rao, Aniruddh and Rudra, Atri and Re, Christopher},
  title     = {Monarch: Expressive Structured Matrices for Efficient and Accurate Training},
  year      = {2022},
  booktitle = {Proceedings of the 39th International Conference on Machine Learning},
  editor    = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  month     = {17--23 Jul},
  pages     = {4690--4721},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {162},
}

@inproceedings{Fu:FlashFFTConv:2024,
  author    = {Daniel Y Fu and Hermann Kumbong and Eric Nguyen and Christopher Re},
  title     = {Flash{FFTC}onv: Efficient Convolutions for Long Sequences with Tensor Cores},
  year      = {2024},
  booktitle = {The Twelfth International Conference on Learning Representations},
  url       = {https://openreview.net/forum?id=gPKTTAfYBp},
}

@inproceedings{Poli:Hyena:2023,
  author    = {Poli, Michael and Massaroli, Stefano and Nguyen, Eric and Fu, Daniel Y. and Dao, Tri and Baccus, Stephen and Bengio, Yoshua and Ermon, Stefano and R\'{e}, Christopher},
  title     = {Hyena hierarchy: towards larger convolutional language models},
  year      = {2023},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  articleno = {1164},
  location  = {Honolulu, Hawaii, USA},
  numpages  = {36},
  publisher = {JMLR.org},
  series    = {ICML'23},
}

@misc{Shoeybi:MegatronLM:2020,
  author        = {Mohammad Shoeybi and Mostofa Patwary and Raul Puri and Patrick LeGresley and Jared Casper and Bryan Catanzaro},
  title         = {Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {1909.08053},
  primaryclass  = {cs.CL},
}

@misc{Vaswani:Attention:2023,
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  title         = {Attention Is All You Need},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {1706.03762},
  primaryclass  = {cs.CL},
}
